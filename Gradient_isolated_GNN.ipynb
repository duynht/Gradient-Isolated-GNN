{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient-isolated GNN",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d086aa7f69647b2af7ada59a431258b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4d37992137de447983a40b93a06a933d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6eef759338ad43489f698b233f5740a5",
              "IPY_MODEL_e5e8e27f341545cc86d7a3c60dd33601"
            ]
          }
        },
        "4d37992137de447983a40b93a06a933d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6eef759338ad43489f698b233f5740a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_885f3d7ad36247e7aa2cff81dd85ba63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd6e1fc954484ed79008d25c83f6e650"
          }
        },
        "e5e8e27f341545cc86d7a3c60dd33601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_737af6960015484794539ace2322f362",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2640404480/? [02:50&lt;00:00, 17973270.25it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8bcad5f4da464fc6bff3340eac657a61"
          }
        },
        "885f3d7ad36247e7aa2cff81dd85ba63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd6e1fc954484ed79008d25c83f6e650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "737af6960015484794539ace2322f362": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8bcad5f4da464fc6bff3340eac657a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duynht/Greedy_InfoMax/blob/master/Gradient_isolated_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y6NeVTYs1Y5",
        "colab_type": "text"
      },
      "source": [
        "# README\n",
        "This notebook houses preliminary experiments for applying gradient-isolated training to Graph Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ucy5n13wO1vn",
        "colab_type": "text"
      },
      "source": [
        "# Keep Colab running in the background\n",
        "Set a JavaScript interval to click on the connect button every 60 seconds. Open developer-settings (in your web-browser) with Ctrl+Shift+I then click on console tab and paste this to the console prompt. (for Mac press Option+Command+I)\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "<!-- function ConnectButton(){\n",
        "    console.log(\"Connect pushed\"); \n",
        "    document.querySelector(\"#connect\").click() \n",
        "}\n",
        "setInterval(ConnectButton,60000); -->\n",
        "```\n",
        "Little did I know Colab changed their selector id with this fancy update so we'll use the now code then. This time we have proper start and stop function. LOLOLOLOLOL\n",
        "\n",
        "```\n",
        "var startClickConnect = function startClickConnect(){\n",
        "    var clickConnect = function clickConnect(){\n",
        "        console.log(\"Connnect Clicked - Start\");\n",
        "        document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click();\n",
        "        console.log(\"Connnect Clicked - End\"); \n",
        "    };\n",
        "\n",
        "    var intervalId = setInterval(clickConnect, 60000);\n",
        "\n",
        "    var stopClickConnectHandler = function stopClickConnect() {\n",
        "        console.log(\"Connnect Clicked Stopped - Start\");\n",
        "        clearInterval(intervalId);\n",
        "        console.log(\"Connnect Clicked Stopped - End\");\n",
        "    };\n",
        "\n",
        "    return stopClickConnectHandler;\n",
        "};\n",
        "\n",
        "var stopClickConnect = startClickConnect();\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55OhTMtw966A",
        "colab_type": "code",
        "outputId": "4fbdb735-6082-498d-a20a-484a8e950c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzvtYMM4_GLw",
        "colab_type": "code",
        "outputId": "e9757f27-4f1e-48a9-a7a4-6317a31e8ca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "!git clone https://github.com/duynht/Greedy_InfoMax.git\n",
        "%cd /content/Greedy_InfoMax"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Greedy_InfoMax'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects:   3% (1/31)\u001b[K\rremote: Counting objects:   6% (2/31)\u001b[K\rremote: Counting objects:   9% (3/31)\u001b[K\rremote: Counting objects:  12% (4/31)\u001b[K\rremote: Counting objects:  16% (5/31)\u001b[K\rremote: Counting objects:  19% (6/31)\u001b[K\rremote: Counting objects:  22% (7/31)\u001b[K\rremote: Counting objects:  25% (8/31)\u001b[K\rremote: Counting objects:  29% (9/31)\u001b[K\rremote: Counting objects:  32% (10/31)\u001b[K\rremote: Counting objects:  35% (11/31)\u001b[K\rremote: Counting objects:  38% (12/31)\u001b[K\rremote: Counting objects:  41% (13/31)\u001b[K\rremote: Counting objects:  45% (14/31)\u001b[K\rremote: Counting objects:  48% (15/31)\u001b[K\rremote: Counting objects:  51% (16/31)\u001b[K\rremote: Counting objects:  54% (17/31)\u001b[K\rremote: Counting objects:  58% (18/31)\u001b[K\rremote: Counting objects:  61% (19/31)\u001b[K\rremote: Counting objects:  64% (20/31)\u001b[K\rremote: Counting objects:  67% (21/31)\u001b[K\rremote: Counting objects:  70% (22/31)\u001b[K\rremote: Counting objects:  74% (23/31)\u001b[K\rremote: Counting objects:  77% (24/31)\u001b[K\rremote: Counting objects:  80% (25/31)\u001b[K\rremote: Counting objects:  83% (26/31)\u001b[K\rremote: Counting objects:  87% (27/31)\u001b[K\rremote: Counting objects:  90% (28/31)\u001b[K\rremote: Counting objects:  93% (29/31)\u001b[K\rremote: Counting objects:  96% (30/31)\u001b[K\rremote: Counting objects: 100% (31/31)\u001b[K\rremote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 376 (delta 16), reused 16 (delta 6), pack-reused 345\u001b[K\n",
            "Receiving objects: 100% (376/376), 35.27 MiB | 19.46 MiB/s, done.\n",
            "Resolving deltas: 100% (208/208), done.\n",
            "/content/Greedy_InfoMax\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isWyIDA7tVty",
        "colab_type": "text"
      },
      "source": [
        "# Graph package installation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cs99CJQtZka",
        "colab_type": "code",
        "outputId": "42c645c6-652a-4130-de90-e15e71e2d5fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting black==19.3b0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/62/cf549544a5fe990bbaeca21e9c419501b2de7a701ab0afb377bc81676600/black-19.3b0-py36-none-any.whl (89kB)\n",
            "\r\u001b[K     |███▋                            | 10kB 23.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 4.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 30kB 5.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 40kB 5.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 51kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 71kB 5.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 81kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt==0.6.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.6.2)\n",
            "Collecting jsonpickle==0.9.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/d5/2f47f03d3f64c31b0d7070b488274631d7567c36e81a9f744e6638bb0f0d/jsonpickle-0.9.6.tar.gz (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 22.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 19.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 40kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 51kB 7.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.0MB/s \n",
            "\u001b[?25hCollecting munch==2.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/68/f4/260ec98ea840757a0da09e0ed8135333d59b8dfebe9752a365b04857660a/munch-2.3.2.tar.gz\n",
            "Collecting py-cpuinfo==5.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/60/63f28a5401da733043abe7053e7d9591491b4784c4f87c339bf51215aa0a/py-cpuinfo-5.0.0.tar.gz (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.4MB/s \n",
            "\u001b[?25hCollecting sacred==0.7.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/25/844c1e9bf5e767b76b9c1df9b7fc8ea323ea8c5065a6bcd9659a33d6db81/sacred-0.7.4-py2.py3-none-any.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 6.7MB/s \n",
            "\u001b[?25hCollecting tensorboardx==1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/76/89dd44458eb976347e5a6e75eb79fecf8facd46c1ce259bad54e0044ea35/tensorboardX-1.6-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 11.3MB/s \n",
            "\u001b[?25hCollecting toml==0.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a2/12/ced7105d2de62fa7c8fb5fce92cc4ce66b57c95fb875e9318dba7f8c5db0/toml-0.10.0-py2.py3-none-any.whl\n",
            "Collecting torchaudio==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/bc/3ebc127162d27bed33dc914606f10117d106680baae7ce83603ea09985fd/torchaudio-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 13.5MB/s \n",
            "\u001b[?25hCollecting torchviz==0.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hCollecting torch-geometric==1.4.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/35/8a65fc0b685d916f5f70199d6ad6f19bb002dc3a547a3fe5b68d60047f3b/torch_geometric-1.4.3.tar.gz (129kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 44.1MB/s \n",
            "\u001b[?25hCollecting torch-scatter==2.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/98/a9/47cd92673b6ba251240d587815c763baac2099b07bb76fecdb3b7ae5cece/torch_scatter-2.0.4.tar.gz\n",
            "Collecting torch-sparse==0.6.1\n",
            "  Downloading https://files.pythonhosted.org/packages/12/9e/66247cbc250e746d06de35c6eb226ec39f4cb4be46adf6ee27527915910b/torch_sparse-0.6.1.tar.gz\n",
            "Collecting torch-cluster==1.5.4\n",
            "  Downloading https://files.pythonhosted.org/packages/08/8b/b483508812fe2242ddf645605ee720822943877b11f820ece1dba5c40fc8/torch_cluster-1.5.4.tar.gz\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 15)) (1.4.0)\n",
            "Collecting appdirs\n",
            "  Downloading https://files.pythonhosted.org/packages/56/eb/810e700ed1349edde4cbdc1b2a21e28cdf115f9faf263f6bbf8447c1abf3/appdirs-1.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from black==19.3b0->-r requirements.txt (line 1)) (19.3.0)\n",
            "Requirement already satisfied: click>=6.5 in /usr/local/lib/python3.6/dist-packages (from black==19.3b0->-r requirements.txt (line 1)) (7.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from munch==2.3.2->-r requirements.txt (line 4)) (1.12.0)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from sacred==0.7.4->-r requirements.txt (line 6)) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardx==1.6->-r requirements.txt (line 7)) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardx==1.6->-r requirements.txt (line 7)) (1.18.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz==0.0.1->-r requirements.txt (line 10)) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.4.3->-r requirements.txt (line 11)) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.4.3->-r requirements.txt (line 11)) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.4.3->-r requirements.txt (line 11)) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.4.3->-r requirements.txt (line 11)) (0.16.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.4.3->-r requirements.txt (line 11)) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.4.3->-r requirements.txt (line 11)) (2.21.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/93/c8/cf47848cd4d661850e4a8e7f0fc4f7298515e06d0da7255ed08e5312d4aa/plyfile-0.7.2-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.4.3->-r requirements.txt (line 11)) (1.0.3)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.4.3->-r requirements.txt (line 11)) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric==1.4.3->-r requirements.txt (line 11)) (0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardx==1.6->-r requirements.txt (line 7)) (46.1.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric==1.4.3->-r requirements.txt (line 11)) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric==1.4.3->-r requirements.txt (line 11)) (0.14.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric==1.4.3->-r requirements.txt (line 11)) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric==1.4.3->-r requirements.txt (line 11)) (7.0.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric==1.4.3->-r requirements.txt (line 11)) (3.2.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric==1.4.3->-r requirements.txt (line 11)) (1.1.1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric==1.4.3->-r requirements.txt (line 11)) (0.31.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric==1.4.3->-r requirements.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric==1.4.3->-r requirements.txt (line 11)) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric==1.4.3->-r requirements.txt (line 11)) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric==1.4.3->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric==1.4.3->-r requirements.txt (line 11)) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric==1.4.3->-r requirements.txt (line 11)) (2018.9)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric==1.4.3->-r requirements.txt (line 11)) (2.4.7)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch-geometric==1.4.3->-r requirements.txt (line 11)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch-geometric==1.4.3->-r requirements.txt (line 11)) (1.2.0)\n",
            "Building wheels for collected packages: jsonpickle, munch, py-cpuinfo, torchviz, torch-geometric, torch-scatter, torch-sparse, torch-cluster\n",
            "  Building wheel for jsonpickle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonpickle: filename=jsonpickle-0.9.6-cp36-none-any.whl size=29466 sha256=374445a579b9f7c20d4f8f6f4672fd0f2a1d137f59f5ed1e053af25645a48324\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/8b/41/8ce98f4737a9ff61b1bf2673f2abfe66a6a43ad6e91d2c9736\n",
            "  Building wheel for munch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for munch: filename=munch-2.3.2-py2.py3-none-any.whl size=6613 sha256=7deab9b3ab159d5057bd9eac92303cfaa5ab7d827d644c97e3ef5c45d4aae35f\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/bf/bc/06a3e1bfe0ab27d2e720ceb3cff3159398d92644c0cec2c125\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-5.0.0-cp36-none-any.whl size=18684 sha256=2b2c9ce0bdc530fc594a92f5711ded7e13e0258a9fcc671ca2d860f656757056\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/7e/a9/b982d0fea22b7e4ae5619de949570cde5ad55420cec16e86a5\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3523 sha256=a3f1afe1e49bbd80ab92a23d555d0a3d5eada786a791f614bfef115c31557aa2\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.4.3-cp36-none-any.whl size=234873 sha256=3e5089509e32defcc281f9ea212a3687199e5b57009f05265f5fc5d2d79e19c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/e2/c1/09/8693feee3f97e440d68b09abfca8b4c1e97150ace350b5003f\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.0.4-cp36-cp36m-linux_x86_64.whl size=11300291 sha256=e9e4b4681ef37759cf69bed42136d6f3992f6e0a6c4fc633958bbf351e39cbf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/28/28/458ddcee4849d5f8a14dd1be1e957d2e8b2955e8c96b07a12d\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.1-cp36-cp36m-linux_x86_64.whl size=16243075 sha256=4a101165eb27d865b887faee29eba09285c4e3b50e5182b054cc91b392dbebb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/73/08/5c819dcb52eb96a5cb31310c39baf658925d14576e61116437\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.5.4-cp36-cp36m-linux_x86_64.whl size=15918616 sha256=c36ce2262edcc8d324932820b23a16c712e780334698a2e89fff00bbc4d5384d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/c0/67/f3702763a38ed07752ebfeca0099966ca9149ab9064d83208f\n",
            "Successfully built jsonpickle munch py-cpuinfo torchviz torch-geometric torch-scatter torch-sparse torch-cluster\n",
            "Installing collected packages: appdirs, toml, black, jsonpickle, munch, py-cpuinfo, sacred, tensorboardx, torchaudio, torchviz, plyfile, isodate, rdflib, torch-geometric, torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed appdirs-1.4.3 black-19.3b0 isodate-0.6.0 jsonpickle-0.9.6 munch-2.3.2 plyfile-0.7.2 py-cpuinfo-5.0.0 rdflib-5.0.0 sacred-0.7.4 tensorboardx-1.6 toml-0.10.0 torch-cluster-1.5.4 torch-geometric-1.4.3 torch-scatter-2.0.4 torch-sparse-0.6.1 torchaudio-0.4.0 torchviz-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvLyaZyjteVO",
        "colab_type": "text"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4XAYrLutQF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as npnpinpi\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import InMemoryDataset\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTAMw8TucquJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "591a1860-e5d2-4eb9-98d1-c47251f6d3a8"
      },
      "source": [
        "from GreedyInfoMax.vision.data import get_dataloader\n",
        "from GreedyInfoMax.vision.arg_parser import arg_parser\n",
        "from GreedyInfoMax.vision.models import load_vision_model, SmallModel\n",
        "from GreedyInfoMax.utils import logger, utils"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyHH0hay_c4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import os.path as osp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afaE0rX7zBw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pdb\n",
        "# breakpoint() # not working for python 3.6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqrglE3UhD1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "if '-f' in sys.argv:\n",
        "  sys.argv.remove('-f')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9H7SBlHOA6I",
        "colab_type": "text"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vbOkPIVEsVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, save_dir=''):\n",
        "  trainloader = DataLoader(stl10_train, batch_size=64, shuffle=True)\n",
        "  testloader = DataLoader(stl10_test, batch_size=64, shuffle=True)\n",
        "  \n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  model.to(device)\n",
        "\n",
        "  best_acc = 0\n",
        "\n",
        "  save_dir = osp.join(\"/content/drive/My Drive/Gradient-isolated GNN\", save_dir)\n",
        "  if not osp.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "  checkpoint = \"acc_{:.4f}--epochs_{}--batch_size_64--dim_9216_512_64_10--optim_Adam_lr_0.003--F_nll_loss.pt\"\n",
        "\n",
        "  epochs = 200\n",
        "  for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    train_acc = 0\n",
        "    model.train()\n",
        "    for batch in trainloader:\n",
        "      optimizer.zero_grad()\n",
        "      batch = batch.to(device)\n",
        "      emb, logits = model(batch)\n",
        "      labels = batch.y\n",
        "      loss = model.loss(logits, labels)\n",
        "      pred = logits.argmax(dim=1) \n",
        "\n",
        "      train_acc += pred.eq(labels).sum().item()\n",
        "      running_loss += loss.item()\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    train_acc /= len(trainloader.dataset)\n",
        "    running_loss /= len(trainloader.dataset)\n",
        "    \n",
        "    # cheating validation = test\n",
        "    \n",
        "    test_acc = test(model, testloader)\n",
        "    if (test_acc >= best_acc):\n",
        "      best_acc = test_acc\n",
        "\n",
        "    if e % 5 == 0:\n",
        "      print(\"Epoch {}/{}. Loss: {:.4f}. Train accuracy: {:.4f}. Test accuracy: {:.4f}\".format(e+1, epochs, running_loss, train_acc, test_acc))\n",
        "\n",
        "    if e == epochs - 1:\n",
        "      print(\"Epoch {}/{}. Loss: {:.4f}. Train accuracy: {:.4f}. Test accuracy: {:.4f}\".format(e+1, epochs, running_loss, train_acc, test_acc))\n",
        "      torch.save(model.state_dict(), osp.join(save_dir,checkpoint.format(test_acc, e+1)))\n",
        "      print(\"Best accuracy: {:.4f}. Last accuracy: {:.4f}\".format(best_acc, test_acc))       \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ4NdLoakAqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, testloader):\n",
        "  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "  accuracy = 0\n",
        "  model.eval()\n",
        "  for batch in testloader:\n",
        "    with torch.no_grad():\n",
        "      batch = batch.to(device)\n",
        "      emb, logits = model(batch)\n",
        "      pred = logits.argmax(dim=1)\n",
        "      labels = batch.y\n",
        "    \n",
        "    accuracy += pred.eq(labels).sum().item()\n",
        "\n",
        "  accuracy /= len(testloader.dataset)\n",
        "  return accuracy\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW9M-UZ2pxY7",
        "colab_type": "text"
      },
      "source": [
        "# Create a Custom Graph Dataset from STL10\n",
        "Each image is divided into a $2\\times2$ grid. Each patch of the grid is a node of the graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXM0yhHgqPZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GraphSTL10(InMemoryDataset):\n",
        "  def __init__(self, root, split):\n",
        "    # !python -m GreedyInfoMax.vision.modded_downstream_classification \\\n",
        "    # --model_path \"/content/drive/My Drive/Greedy_InfoMax/logs/modded_vision_experiment_module_all\" \\\n",
        "    # --model_num 5 \\\n",
        "    # --download_dataset\n",
        "    self.opt = arg_parser.parse_args()\n",
        "    self.opt.download_dataset=True\n",
        "    self.opt.model_path = \"/content/drive/My Drive/pretrainted-resnet50-infomax\"\n",
        "    self.opt.model_num = 5    \n",
        "    \n",
        "    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    self.context_models = []\n",
        "    for pid in range(4):\n",
        "      context_model, _ = load_vision_model.load_model_and_optimizer(\n",
        "                self.opt, reload_model=True, calc_loss=False, patch_idx=pid)\n",
        "      context_model.module.switch_calc_loss(False)\n",
        "      for param in context_model.parameters():\n",
        "        param.requires_grad = False\n",
        "      context_model.eval()\n",
        "      context_model.to(self.device)\n",
        "      self.context_models.append(context_model)\n",
        "      \n",
        "    self.dataloader = None\n",
        "\n",
        "    _, _, trainloader, _, testloader, _ = get_dataloader.get_dataloader(self.opt)\n",
        "    self.split = split\n",
        "    if (split == 'train'):\n",
        "      # self.dataset = datasets.STL10(root='/tmp/stl10_train', split='train', download=True)\n",
        "      self.dataloader = trainloader\n",
        "    if (split == 'test'):\n",
        "      # self.dataset = datasets.STL10(root='/tmp/stl10_test', split='test', download=True)\n",
        "       self.dataloader = testloader\n",
        "    \n",
        "    super(GraphSTL10, self).__init__(root)\n",
        "    # self.num_classes = 10\n",
        "    self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return []\n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    if (self.split == 'train'):\n",
        "      return ['graphstl10_train.pt']\n",
        "    if (self.split == 'test'):\n",
        "      return ['graphstl10_test.pt']\n",
        "    \n",
        "    return []\n",
        "\n",
        "  def download(self):\n",
        "    pass\n",
        "\n",
        "  def process(self):\n",
        "    \n",
        "    \"\"\"Pytorch ResNet50\n",
        "    # def crop(image,pc_height,pc_width):\n",
        "    #   im_width, im_height = image.size\n",
        "    #   for i in range(im_height//pc_height):\n",
        "    #     for j in range(im_width//pc_width):\n",
        "    #       box = (j*pc_width, i*pc_height, (j+1)*pc_width, (i+1)*pc_height)\n",
        "    #       yield image.crop(box)\n",
        "\n",
        "    # data_list = []\n",
        "\n",
        "    # preprocess = transforms.Compose([transforms.Resize(256),\n",
        "    #                                     transforms.CenterCrop(224),\n",
        "    #                                     transforms.ToTensor(),\n",
        "    #                                     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "    # resnet50 = models.resnet50(pretrained=True)\n",
        "    # resnet50.fc = nn.Identity()\n",
        "\n",
        "    # for param in resnet50.parameters():\n",
        "    #   param.requires_grad = False\n",
        "\n",
        "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # resnet50.to(device)\n",
        "\n",
        "    # source_nodes = [i for i in range(0,4) for j in range(0,4)]\n",
        "    # target_nodes = [j for i in range(0,4) for j in range(0,4)]\n",
        "    # edge_index = torch.tensor([source_nodes, target_nodes],dtype = torch.long)\n",
        "\n",
        "    # for imid, (image, label) in enumerate(self.dataset):\n",
        "    #   # neighbors = np.arange(imid, imid+4)\n",
        "    #   # mask = [1]*len(neighbors)\n",
        "    #   im_height, im_width = image.size\n",
        "    #   pc_height, pc_width = im_height//2, im_width//2\n",
        "    #   node_features = []\n",
        "    #   for pid,piece in enumerate(crop(image, pc_height, pc_width)):\n",
        "    #     patch = Image.new('RGB', (pc_width, pc_height), 255)\n",
        "    #     patch.paste(piece)\n",
        "    #     patch = preprocess(patch)\n",
        "    #     patch = patch.view(1,*patch.shape)\n",
        "    #     patch = patch.to(device)\n",
        "    #     patch = resnet50.forward(patch).to(torch.device('cpu'))\n",
        "    #     node_features.append(torch.tensor(patch))\n",
        "    \"\"\"\n",
        "\n",
        "    source_nodes = [i for i in range(0,4) for j in range(0,4)]\n",
        "    target_nodes = [j for i in range(0,4) for j in range(0,4)]\n",
        "    edge_index = torch.tensor([source_nodes, target_nodes],dtype = torch.long)\n",
        "\n",
        "    data_list = []\n",
        "\n",
        "    for bid, (imgs, labels) in enumerate(self.dataloader):\n",
        "      batch_size, num_channels, img_height, img_width = imgs.shape\n",
        "      if not(batch_size == self.opt.batch_size_multiGPU):\n",
        "        continue\n",
        "      patches = []\n",
        "      node_features = []\n",
        "      patches.append(imgs[:,:, :img_height//2, :img_width//2])\n",
        "      patches.append(imgs[:,:, :img_height//2, img_width//2:])\n",
        "      patches.append(imgs[:,:, img_height//2:, :img_width//2])\n",
        "      patches.append(imgs[:,:, img_height//2:, img_width//2:])\n",
        "      for pid in range(4):\n",
        "        patch = patches[pid].to(self.device)\n",
        "        patch = self.context_models[pid](patch,labels)[2]\n",
        "        patch = patch.to(torch.device('cpu'))\n",
        "        node_features.append(patch)\n",
        "\n",
        "      node_features = torch.stack(node_features)\n",
        "      node_features = node_features.transpose(0,1)\n",
        "      node_features = node_features.view(*node_features.shape[:-3],-1)\n",
        "      # pdb.set_trace()\n",
        "      labels = labels.to(torch.device('cpu'))\n",
        "      for gid in range(batch_size):  \n",
        "        data = Data(x=node_features[gid], edge_index=edge_index.clone(), y=labels[gid].unsqueeze(0))\n",
        "        data_list.append(data)\n",
        "      # pdb.set_trace()\n",
        "    \n",
        "    data, slices = self.collate(data_list)\n",
        "    torch.save((data, slices), self.processed_paths[0])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVAPxv4G_6ia",
        "colab_type": "code",
        "outputId": "17a068fb-6a3b-4ba2-e1c2-ad6f0fb08007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0d086aa7f69647b2af7ada59a431258b",
            "4d37992137de447983a40b93a06a933d",
            "6eef759338ad43489f698b233f5740a5",
            "e5e8e27f341545cc86d7a3c60dd33601",
            "885f3d7ad36247e7aa2cff81dd85ba63",
            "bd6e1fc954484ed79008d25c83f6e650",
            "737af6960015484794539ace2322f362",
            "8bcad5f4da464fc6bff3340eac657a61"
          ]
        }
      },
      "source": [
        "stl10_train = GraphSTL10('/graphstl10/',split='train')\n",
        "stl10_test = GraphSTL10('/graphstl10/',split='test')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Contrasting against  16  negative samples\n",
            "ModuleList(\n",
            "  (0): ModuleList(\n",
            "    (0): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (Conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (1): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (2): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (4): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (5): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Let's use 1 GPUs!\n",
            "Loading weights from  /content/drive/My Drive/pretrainted-resnet50-infomax\n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Contrasting against  16  negative samples\n",
            "ModuleList(\n",
            "  (0): ModuleList(\n",
            "    (0): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (Conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (1): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (2): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (4): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (5): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Let's use 1 GPUs!\n",
            "Loading weights from  /content/drive/My Drive/pretrainted-resnet50-infomax\n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Contrasting against  16  negative samples\n",
            "ModuleList(\n",
            "  (0): ModuleList(\n",
            "    (0): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (Conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (1): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (2): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (4): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (5): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Let's use 1 GPUs!\n",
            "Loading weights from  /content/drive/My Drive/pretrainted-resnet50-infomax\n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Contrasting against  16  negative samples\n",
            "ModuleList(\n",
            "  (0): ModuleList(\n",
            "    (0): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (Conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (1): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (2): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (4): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (5): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Let's use 1 GPUs!\n",
            "Loading weights from  /content/drive/My Drive/pretrainted-resnet50-infomax\n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./datasets/stl10_binary/stl10_binary.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d086aa7f69647b2af7ada59a431258b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./datasets/stl10_binary/stl10_binary.tar.gz to ./datasets/stl10_binary\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Use (train+val) / test split\n",
            "Processing...\n",
            "Done!\n",
            "Contrasting against  16  negative samples\n",
            "ModuleList(\n",
            "  (0): ModuleList(\n",
            "    (0): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (Conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (1): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (2): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (4): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (5): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Let's use 1 GPUs!\n",
            "Loading weights from  /content/drive/My Drive/pretrainted-resnet50-infomax\n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Contrasting against  16  negative samples\n",
            "ModuleList(\n",
            "  (0): ModuleList(\n",
            "    (0): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (Conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (1): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (2): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (4): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (5): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Let's use 1 GPUs!\n",
            "Loading weights from  /content/drive/My Drive/pretrainted-resnet50-infomax\n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Contrasting against  16  negative samples\n",
            "ModuleList(\n",
            "  (0): ModuleList(\n",
            "    (0): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (Conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (1): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (2): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (4): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (5): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Let's use 1 GPUs!\n",
            "Loading weights from  /content/drive/My Drive/pretrainted-resnet50-infomax\n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Contrasting against  16  negative samples\n",
            "ModuleList(\n",
            "  (0): ModuleList(\n",
            "    (0): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (Conv1): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (1): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "    (2): ResNet_Encoder(\n",
            "      (model): Sequential(\n",
            "        (layer 0): Sequential(\n",
            "          (0): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (shortcut): Sequential(\n",
            "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
            "            )\n",
            "          )\n",
            "          (1): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (2): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (3): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (4): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (5): PreActBottleneckNoBN(\n",
            "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (loss): InfoNCE_Loss(\n",
            "        (W_k): ModuleList(\n",
            "          (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (4): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (contrast_loss): ExpNLLLoss()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Let's use 1 GPUs!\n",
            "Loading weights from  /content/drive/My Drive/pretrainted-resnet50-infomax\n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Error(s) in loading state_dict for ResNet_Encoder:\n",
            "\tUnexpected key(s) in state_dict: \"loss.W_k.5.weight\". \n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Use (train+val) / test split\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0VbJFx1t3U4",
        "colab_type": "text"
      },
      "source": [
        "# Define custom MessagePassing [WIP]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l-qzzdJxAh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomConv(pyg_nn.MessagePassing):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(CustomConv, self).__init__(aggr='add') #'add' aggregation\n",
        "    self.lin = nn.Linear(in_channels, out_channels)\n",
        "    self.lin_self = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # x has shape [N, in_channels]\n",
        "    # edge_index has shape [2, E]\n",
        "\n",
        "    # Transform node feature matrix\n",
        "    self_x = self.lin_self(x)\n",
        "    # x = self.lin(x)\n",
        "\n",
        "    return self_x + self.propagate(edge_index, size=(x.size(0), x.size(0)), x=self.lin(x))\n",
        "  \n",
        "  def message(self, x_i, x_j, edge_index, size):\n",
        "    # Compute messages\n",
        "    # x_j has shape [E, out_channels]\n",
        "    # TODO:\n",
        "    row, col = edge_index\n",
        "    deg = pyg_utils.degree(row, size[0], dtype=x_j.dtype)\n",
        "    deg_inv_sqrt = deg.pow(-0.5)\n",
        "    norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "    return x_j\n",
        "\n",
        "  def update(self, aggr_out):\n",
        "    # aggr_out has shape [N, out_channels]\n",
        "    return aggr_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FisgdFj8uByD",
        "colab_type": "text"
      },
      "source": [
        "# Define the Graph Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGgJDe67NZlE",
        "colab_type": "text"
      },
      "source": [
        "## Graph Convolutional Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stn49Kp4uFf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GCN(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super(GCN, self).__init__()\n",
        "        \n",
        "    self.dropout = 0.25\n",
        "    self.num_layers = 2\n",
        "    self.hidden = [input_dim, 512, hidden_dim]\n",
        "    # self.resnet = models.resnet50(pretrained=True)\n",
        "    # self.resnet.fc = nn.Identity()\n",
        "\n",
        "    self.convs = nn.ModuleList()\n",
        "    self.lns = nn.ModuleList()\n",
        "\n",
        "    for l in range(self.num_layers):\n",
        "      self.convs.append(self.build_conv_model(self.hidden[l], self.hidden[l+1]))\n",
        "      if (l + 1 < self.num_layers):\n",
        "        self.lns.append(nn.LayerNorm(self.hidden[l+1]))\n",
        "\n",
        "    # post-message-passing\n",
        "    self.post_mp = nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25),\n",
        "        nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "  def build_conv_model(self, input_dim, hidden_dim):\n",
        "      return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
        "      \n",
        "  def forward(self, data):\n",
        "    x, edge_index = data.x, data.edge_index\n",
        "    if data.num_node_features == 0:\n",
        "      x = torch.ones(data.num_nodes, 1)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.convs[i](x, edge_index)\n",
        "      emb = x\n",
        "      x = F.relu(x)\n",
        "      x = F.dropout(x, p=self.dropout, training = self.training)\n",
        "      if not i == self.num_layers - 1:\n",
        "        x = self.lns[i](x)\n",
        "\n",
        "    x = pyg_nn.global_mean_pool(x, data.batch)\n",
        "    # x = pyg_nn.global_add_pool(x, data.batch)\n",
        "\n",
        "    x = self.post_mp(x)\n",
        "\n",
        "    return emb, F.log_softmax(x, dim=1)\n",
        "\n",
        "  def loss(self, pred, label):\n",
        "    # Negative log-likelihood\n",
        "    return F.nll_loss(pred, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCjwU3pJ-3mA",
        "colab_type": "code",
        "outputId": "8aeaa309-ebae-4d58-9a64-b3d46a126276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        }
      },
      "source": [
        "model = GCN(input_dim=stl10_train.num_node_features, hidden_dim=64, output_dim = 10)\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.003)\n",
        "train(model, optimizer)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200. Loss: 0.0280. Train accuracy: 0.2959. Test accuracy: 0.4051\n",
            "Epoch 6/200. Loss: 0.0140. Train accuracy: 0.6683. Test accuracy: 0.4735\n",
            "Epoch 11/200. Loss: 0.0053. Train accuracy: 0.8840. Test accuracy: 0.4571\n",
            "Epoch 16/200. Loss: 0.0028. Train accuracy: 0.9389. Test accuracy: 0.4579\n",
            "Epoch 21/200. Loss: 0.0018. Train accuracy: 0.9619. Test accuracy: 0.4635\n",
            "Epoch 26/200. Loss: 0.0012. Train accuracy: 0.9762. Test accuracy: 0.4650\n",
            "Epoch 31/200. Loss: 0.0015. Train accuracy: 0.9710. Test accuracy: 0.4539\n",
            "Epoch 36/200. Loss: 0.0011. Train accuracy: 0.9804. Test accuracy: 0.4622\n",
            "Epoch 41/200. Loss: 0.0006. Train accuracy: 0.9872. Test accuracy: 0.4636\n",
            "Epoch 46/200. Loss: 0.0008. Train accuracy: 0.9846. Test accuracy: 0.4606\n",
            "Epoch 51/200. Loss: 0.0006. Train accuracy: 0.9910. Test accuracy: 0.4654\n",
            "Epoch 56/200. Loss: 0.0014. Train accuracy: 0.9728. Test accuracy: 0.4710\n",
            "Epoch 61/200. Loss: 0.0007. Train accuracy: 0.9882. Test accuracy: 0.4609\n",
            "Epoch 66/200. Loss: 0.0007. Train accuracy: 0.9882. Test accuracy: 0.4696\n",
            "Epoch 71/200. Loss: 0.0008. Train accuracy: 0.9858. Test accuracy: 0.4552\n",
            "Epoch 76/200. Loss: 0.0009. Train accuracy: 0.9854. Test accuracy: 0.4662\n",
            "Epoch 81/200. Loss: 0.0007. Train accuracy: 0.9884. Test accuracy: 0.4536\n",
            "Epoch 86/200. Loss: 0.0007. Train accuracy: 0.9896. Test accuracy: 0.4532\n",
            "Epoch 91/200. Loss: 0.0008. Train accuracy: 0.9868. Test accuracy: 0.4517\n",
            "Epoch 96/200. Loss: 0.0008. Train accuracy: 0.9868. Test accuracy: 0.4495\n",
            "Epoch 101/200. Loss: 0.0006. Train accuracy: 0.9908. Test accuracy: 0.4627\n",
            "Epoch 106/200. Loss: 0.0008. Train accuracy: 0.9878. Test accuracy: 0.4475\n",
            "Epoch 111/200. Loss: 0.0006. Train accuracy: 0.9930. Test accuracy: 0.4575\n",
            "Epoch 116/200. Loss: 0.0006. Train accuracy: 0.9912. Test accuracy: 0.4612\n",
            "Epoch 121/200. Loss: 0.0005. Train accuracy: 0.9924. Test accuracy: 0.4594\n",
            "Epoch 126/200. Loss: 0.0006. Train accuracy: 0.9904. Test accuracy: 0.4606\n",
            "Epoch 131/200. Loss: 0.0006. Train accuracy: 0.9902. Test accuracy: 0.4541\n",
            "Epoch 136/200. Loss: 0.0005. Train accuracy: 0.9912. Test accuracy: 0.4529\n",
            "Epoch 141/200. Loss: 0.0005. Train accuracy: 0.9910. Test accuracy: 0.4556\n",
            "Epoch 146/200. Loss: 0.0003. Train accuracy: 0.9958. Test accuracy: 0.4515\n",
            "Epoch 151/200. Loss: 0.0003. Train accuracy: 0.9934. Test accuracy: 0.4657\n",
            "Epoch 156/200. Loss: 0.0002. Train accuracy: 0.9966. Test accuracy: 0.4522\n",
            "Epoch 161/200. Loss: 0.0008. Train accuracy: 0.9878. Test accuracy: 0.4525\n",
            "Epoch 166/200. Loss: 0.0007. Train accuracy: 0.9900. Test accuracy: 0.4492\n",
            "Epoch 171/200. Loss: 0.0006. Train accuracy: 0.9920. Test accuracy: 0.4440\n",
            "Epoch 176/200. Loss: 0.0002. Train accuracy: 0.9972. Test accuracy: 0.4669\n",
            "Epoch 181/200. Loss: 0.0003. Train accuracy: 0.9956. Test accuracy: 0.4614\n",
            "Epoch 186/200. Loss: 0.0002. Train accuracy: 0.9970. Test accuracy: 0.4660\n",
            "Epoch 191/200. Loss: 0.0003. Train accuracy: 0.9956. Test accuracy: 0.4670\n",
            "Epoch 196/200. Loss: 0.0004. Train accuracy: 0.9926. Test accuracy: 0.4519\n",
            "Epoch 200/200. Loss: 0.0004. Train accuracy: 0.9924. Test accuracy: 0.4551\n",
            "Best accuracy: 0.4784. Last accuracy: 0.4551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oLkdsJTNlV7",
        "colab_type": "text"
      },
      "source": [
        "## Graph Attention Network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEbtFRWfM5pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GAT(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super(GAT, self).__init__()\n",
        "        \n",
        "    self.dropout = 0.25\n",
        "    self.num_layers = 2\n",
        "    self.hidden = [input_dim, 512, hidden_dim]\n",
        "    # self.resnet = models.resnet50(pretrained=True)\n",
        "    # self.resnet.fc = nn.Identity()\n",
        "\n",
        "    self.convs = nn.ModuleList()\n",
        "    self.lns = nn.ModuleList()\n",
        "\n",
        "    for l in range(self.num_layers):\n",
        "      self.convs.append(self.build_conv_model(self.hidden[l], self.hidden[l+1]))\n",
        "      if (l + 1 < self.num_layers):\n",
        "        self.lns.append(nn.LayerNorm(self.hidden[l+1]))\n",
        "\n",
        "    # post-message-passing\n",
        "    self.post_mp = nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25),\n",
        "        nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "  def build_conv_model(self, input_dim, hidden_dim):\n",
        "      return pyg_nn.GATConv(input_dim, hidden_dim)\n",
        "      \n",
        "  def forward(self, data):\n",
        "    x, edge_index = data.x, data.edge_index\n",
        "    if data.num_node_features == 0:\n",
        "      x = torch.ones(data.num_nodes, 1)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.convs[i](x, edge_index)\n",
        "      emb = x\n",
        "      x = F.relu(x)\n",
        "      x = F.dropout(x, p=self.dropout, training = self.training)\n",
        "      if not i == self.num_layers - 1:\n",
        "        x = self.lns[i](x)\n",
        "\n",
        "    x = pyg_nn.global_mean_pool(x, data.batch)\n",
        "    # x = pyg_nn.global_add_pool(x, data.batch)\n",
        "\n",
        "    x = self.post_mp(x)\n",
        "\n",
        "    return emb, F.log_softmax(x, dim=1)\n",
        "\n",
        "  def loss(self, pred, label):\n",
        "    # Negative log-likelihood\n",
        "    return F.nll_loss(pred, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ6XCvnmOd4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "17edb5ff-baa2-4283-b3e6-19ddd833fba2"
      },
      "source": [
        "model = GAT(input_dim=stl10_train.num_node_features, hidden_dim=64, output_dim = 10)\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.003)\n",
        "train(model, optimizer, save_dir='ResNet50-GreedyInfoMax-GAT')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200. Loss: 0.0301. Train accuracy: 0.2540. Test accuracy: 0.3399\n",
            "Epoch 6/200. Loss: 0.0215. Train accuracy: 0.4914. Test accuracy: 0.3801\n",
            "Epoch 11/200. Loss: 0.0132. Train accuracy: 0.6957. Test accuracy: 0.3698\n",
            "Epoch 16/200. Loss: 0.0073. Train accuracy: 0.8347. Test accuracy: 0.3721\n",
            "Epoch 21/200. Loss: 0.0047. Train accuracy: 0.8936. Test accuracy: 0.3751\n",
            "Epoch 26/200. Loss: 0.0037. Train accuracy: 0.9229. Test accuracy: 0.3655\n",
            "Epoch 31/200. Loss: 0.0032. Train accuracy: 0.9315. Test accuracy: 0.3656\n",
            "Epoch 36/200. Loss: 0.0017. Train accuracy: 0.9649. Test accuracy: 0.3668\n",
            "Epoch 41/200. Loss: 0.0020. Train accuracy: 0.9595. Test accuracy: 0.3636\n",
            "Epoch 46/200. Loss: 0.0016. Train accuracy: 0.9675. Test accuracy: 0.3690\n",
            "Epoch 51/200. Loss: 0.0015. Train accuracy: 0.9698. Test accuracy: 0.3595\n",
            "Epoch 56/200. Loss: 0.0017. Train accuracy: 0.9661. Test accuracy: 0.3628\n",
            "Epoch 61/200. Loss: 0.0012. Train accuracy: 0.9744. Test accuracy: 0.3589\n",
            "Epoch 66/200. Loss: 0.0019. Train accuracy: 0.9663. Test accuracy: 0.3596\n",
            "Epoch 71/200. Loss: 0.0011. Train accuracy: 0.9786. Test accuracy: 0.3639\n",
            "Epoch 76/200. Loss: 0.0012. Train accuracy: 0.9760. Test accuracy: 0.3564\n",
            "Epoch 81/200. Loss: 0.0014. Train accuracy: 0.9742. Test accuracy: 0.3626\n",
            "Epoch 86/200. Loss: 0.0014. Train accuracy: 0.9730. Test accuracy: 0.3646\n",
            "Epoch 91/200. Loss: 0.0009. Train accuracy: 0.9818. Test accuracy: 0.3640\n",
            "Epoch 96/200. Loss: 0.0013. Train accuracy: 0.9768. Test accuracy: 0.3681\n",
            "Epoch 101/200. Loss: 0.0013. Train accuracy: 0.9784. Test accuracy: 0.3626\n",
            "Epoch 106/200. Loss: 0.0009. Train accuracy: 0.9856. Test accuracy: 0.3666\n",
            "Epoch 111/200. Loss: 0.0010. Train accuracy: 0.9800. Test accuracy: 0.3679\n",
            "Epoch 116/200. Loss: 0.0009. Train accuracy: 0.9818. Test accuracy: 0.3599\n",
            "Epoch 121/200. Loss: 0.0011. Train accuracy: 0.9796. Test accuracy: 0.3550\n",
            "Epoch 126/200. Loss: 0.0008. Train accuracy: 0.9880. Test accuracy: 0.3576\n",
            "Epoch 131/200. Loss: 0.0007. Train accuracy: 0.9870. Test accuracy: 0.3645\n",
            "Epoch 136/200. Loss: 0.0012. Train accuracy: 0.9784. Test accuracy: 0.3698\n",
            "Epoch 141/200. Loss: 0.0009. Train accuracy: 0.9848. Test accuracy: 0.3633\n",
            "Epoch 146/200. Loss: 0.0011. Train accuracy: 0.9812. Test accuracy: 0.3669\n",
            "Epoch 151/200. Loss: 0.0004. Train accuracy: 0.9932. Test accuracy: 0.3639\n",
            "Epoch 156/200. Loss: 0.0011. Train accuracy: 0.9814. Test accuracy: 0.3629\n",
            "Epoch 161/200. Loss: 0.0007. Train accuracy: 0.9878. Test accuracy: 0.3664\n",
            "Epoch 166/200. Loss: 0.0008. Train accuracy: 0.9848. Test accuracy: 0.3624\n",
            "Epoch 171/200. Loss: 0.0004. Train accuracy: 0.9920. Test accuracy: 0.3616\n",
            "Epoch 176/200. Loss: 0.0006. Train accuracy: 0.9912. Test accuracy: 0.3718\n",
            "Epoch 181/200. Loss: 0.0006. Train accuracy: 0.9872. Test accuracy: 0.3680\n",
            "Epoch 186/200. Loss: 0.0003. Train accuracy: 0.9942. Test accuracy: 0.3564\n",
            "Epoch 191/200. Loss: 0.0009. Train accuracy: 0.9854. Test accuracy: 0.3501\n",
            "Epoch 196/200. Loss: 0.0008. Train accuracy: 0.9894. Test accuracy: 0.3609\n",
            "Epoch 200/200. Loss: 0.0007. Train accuracy: 0.9846. Test accuracy: 0.3601\n",
            "Best accuracy: 0.3904. Last accuracy: 0.3601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqt07bM_Nh4q",
        "colab_type": "text"
      },
      "source": [
        "## Attention-based Graph Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3NAzRBfJqAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AGNN(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super(AGNN, self).__init__()\n",
        "        \n",
        "    self.dropout = 0.25\n",
        "    self.num_layers = 2\n",
        "    self.hidden = [input_dim, 512, hidden_dim]\n",
        "    # self.resnet = models.resnet50(pretrained=True)\n",
        "    # self.resnet.fc = nn.Identity()\n",
        "\n",
        "    self.convs = nn.ModuleList()\n",
        "    self.lns = nn.ModuleList()\n",
        "    self.attention = pyg_nn.AGNNConv()\n",
        "\n",
        "    for l in range(self.num_layers):\n",
        "      self.convs.append(self.build_conv_model(self.hidden[l], self.hidden[l+1]))\n",
        "      if (l + 1 < self.num_layers):\n",
        "        self.lns.append(nn.LayerNorm(self.hidden[l+1]))\n",
        "\n",
        "    # post-message-passing\n",
        "    self.post_mp = nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25),\n",
        "        nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "  def build_conv_model(self, input_dim, hidden_dim):\n",
        "      return nn.Linear(input_dim, hidden_dim)\n",
        "      \n",
        "  def forward(self, data):\n",
        "    x, edge_index = data.x, data.edge_index\n",
        "    if data.num_node_features == 0:\n",
        "      x = torch.ones(data.num_nodes, 1)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.attention(self.convs[i](x), edge_index)\n",
        "      emb = x\n",
        "      x = F.relu(x)\n",
        "      x = F.dropout(x, p=self.dropout, training = self.training)\n",
        "      if not i == self.num_layers - 1:\n",
        "        x = self.lns[i](x)\n",
        "\n",
        "    x = pyg_nn.global_mean_pool(x, data.batch)\n",
        "    # x = pyg_nn.global_add_pool(x, data.batch)\n",
        "\n",
        "    x = self.post_mp(x)\n",
        "\n",
        "    return emb, F.log_softmax(x, dim=1)\n",
        "\n",
        "  def loss(self, pred, label):\n",
        "    # Negative log-likelihood\n",
        "    return F.nll_loss(pred, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I83VKBVKOZOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "outputId": "8fe860ea-8a65-4357-92d3-3a71dd2e929c"
      },
      "source": [
        "model = AGNN(input_dim=stl10_train.num_node_features, hidden_dim=64, output_dim = 10)\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.003)\n",
        "train(model, optimizer, save_dir=\"ResNet50-GreedyInfoMax-AGNN\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200. Loss: 0.0281. Train accuracy: 0.2849. Test accuracy: 0.3760\n",
            "Epoch 6/200. Loss: 0.0129. Train accuracy: 0.6963. Test accuracy: 0.4730\n",
            "Epoch 11/200. Loss: 0.0046. Train accuracy: 0.8992. Test accuracy: 0.4672\n",
            "Epoch 16/200. Loss: 0.0018. Train accuracy: 0.9607. Test accuracy: 0.4635\n",
            "Epoch 21/200. Loss: 0.0015. Train accuracy: 0.9692. Test accuracy: 0.4541\n",
            "Epoch 26/200. Loss: 0.0015. Train accuracy: 0.9722. Test accuracy: 0.4689\n",
            "Epoch 31/200. Loss: 0.0012. Train accuracy: 0.9748. Test accuracy: 0.4641\n",
            "Epoch 36/200. Loss: 0.0014. Train accuracy: 0.9740. Test accuracy: 0.4590\n",
            "Epoch 41/200. Loss: 0.0007. Train accuracy: 0.9856. Test accuracy: 0.4625\n",
            "Epoch 46/200. Loss: 0.0005. Train accuracy: 0.9904. Test accuracy: 0.4695\n",
            "Epoch 51/200. Loss: 0.0015. Train accuracy: 0.9698. Test accuracy: 0.4482\n",
            "Epoch 56/200. Loss: 0.0008. Train accuracy: 0.9842. Test accuracy: 0.4582\n",
            "Epoch 61/200. Loss: 0.0007. Train accuracy: 0.9844. Test accuracy: 0.4557\n",
            "Epoch 66/200. Loss: 0.0007. Train accuracy: 0.9864. Test accuracy: 0.4695\n",
            "Epoch 71/200. Loss: 0.0005. Train accuracy: 0.9908. Test accuracy: 0.4575\n",
            "Epoch 76/200. Loss: 0.0010. Train accuracy: 0.9808. Test accuracy: 0.4684\n",
            "Epoch 81/200. Loss: 0.0007. Train accuracy: 0.9890. Test accuracy: 0.4659\n",
            "Epoch 86/200. Loss: 0.0004. Train accuracy: 0.9942. Test accuracy: 0.4577\n",
            "Epoch 91/200. Loss: 0.0009. Train accuracy: 0.9840. Test accuracy: 0.4604\n",
            "Epoch 96/200. Loss: 0.0006. Train accuracy: 0.9904. Test accuracy: 0.4594\n",
            "Epoch 101/200. Loss: 0.0007. Train accuracy: 0.9884. Test accuracy: 0.4566\n",
            "Epoch 106/200. Loss: 0.0006. Train accuracy: 0.9896. Test accuracy: 0.4639\n",
            "Epoch 111/200. Loss: 0.0007. Train accuracy: 0.9900. Test accuracy: 0.4660\n",
            "Epoch 116/200. Loss: 0.0004. Train accuracy: 0.9940. Test accuracy: 0.4688\n",
            "Epoch 121/200. Loss: 0.0008. Train accuracy: 0.9878. Test accuracy: 0.4686\n",
            "Epoch 126/200. Loss: 0.0008. Train accuracy: 0.9850. Test accuracy: 0.4487\n",
            "Epoch 131/200. Loss: 0.0003. Train accuracy: 0.9940. Test accuracy: 0.4706\n",
            "Epoch 136/200. Loss: 0.0005. Train accuracy: 0.9928. Test accuracy: 0.4696\n",
            "Epoch 141/200. Loss: 0.0004. Train accuracy: 0.9940. Test accuracy: 0.4661\n",
            "Epoch 146/200. Loss: 0.0006. Train accuracy: 0.9906. Test accuracy: 0.4716\n",
            "Epoch 151/200. Loss: 0.0004. Train accuracy: 0.9938. Test accuracy: 0.4591\n",
            "Epoch 156/200. Loss: 0.0003. Train accuracy: 0.9950. Test accuracy: 0.4740\n",
            "Epoch 161/200. Loss: 0.0002. Train accuracy: 0.9966. Test accuracy: 0.4662\n",
            "Epoch 166/200. Loss: 0.0003. Train accuracy: 0.9956. Test accuracy: 0.4706\n",
            "Epoch 171/200. Loss: 0.0005. Train accuracy: 0.9940. Test accuracy: 0.4585\n",
            "Epoch 176/200. Loss: 0.0005. Train accuracy: 0.9912. Test accuracy: 0.4664\n",
            "Epoch 181/200. Loss: 0.0002. Train accuracy: 0.9968. Test accuracy: 0.4596\n",
            "Epoch 186/200. Loss: 0.0003. Train accuracy: 0.9958. Test accuracy: 0.4621\n",
            "Epoch 191/200. Loss: 0.0003. Train accuracy: 0.9952. Test accuracy: 0.4624\n",
            "Epoch 196/200. Loss: 0.0004. Train accuracy: 0.9928. Test accuracy: 0.4674\n",
            "Epoch 200/200. Loss: 0.0005. Train accuracy: 0.9926. Test accuracy: 0.4627\n",
            "Best accuracy: 0.4771. Last accuracy: 0.4627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AqkwLEp89fi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%debug"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}