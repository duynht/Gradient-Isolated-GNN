{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradient-isolated GNN",
      "provenance": [],
      "authorship_tag": "ABX9TyOqwNDoXyAYqleJmUOQWM6X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duynht/Greedy_InfoMax/blob/master/Gradient_isolated_GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Y6NeVTYs1Y5",
        "colab_type": "text"
      },
      "source": [
        "# README\n",
        "This notebook houses preliminary experiments for applying gradient-isolated training to Graph Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isWyIDA7tVty",
        "colab_type": "text"
      },
      "source": [
        "# Graph package installation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cs99CJQtZka",
        "colab_type": "code",
        "outputId": "6a0d0ecc-fe3a-4d5d-a456-4d5bb54331f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        }
      },
      "source": [
        "!pip install torch-scatter\n",
        "!pip install torch-sparse\n",
        "!pip install torch-cluster\n",
        "!pip install torch-geometric\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.6/dist-packages (2.0.4)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse) (1.18.2)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.6/dist-packages (1.5.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-cluster) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-cluster) (1.18.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.6/dist-packages (1.4.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.16.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.21.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.2)\n",
            "Requirement already satisfied: plyfile in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.7.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.2.2)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.0.3)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (46.1.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (7.0.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch-geometric) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.4.5.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch-geometric) (1.12.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch-geometric) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch-geometric) (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1faf88eb-d6ab-43a1-f200-b4973f8d47e2",
        "id": "DKjL2HsqLqdx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!pip install tensorboardX"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (46.1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvLyaZyjteVO",
        "colab_type": "text"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4XAYrLutQF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import InMemoryDataset\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os.path as osp\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW9M-UZ2pxY7",
        "colab_type": "text"
      },
      "source": [
        "# Create a Custom Graph Dataset from STL10\n",
        "Each image is divided into a $2\\times2$ grid. Each patch of the grid is a node of the graph.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXM0yhHgqPZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GraphSTL10(InMemoryDataset):\n",
        "  def __init__(self, root, split):\n",
        "    self.split = split\n",
        "    if (split == 'train'):\n",
        "      self.dataset = datasets.STL10(root='/tmp/stl10_train', split='train', download=True)\n",
        "    if (split == 'test'):\n",
        "      self.dataset = datasets.STL10(root='/tmp/stl10_test', split='test', download=True)\n",
        "    super(GraphSTL10, self).__init__(root)\n",
        "    # self.num_classes = 10\n",
        "    self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return []\n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    if (self.split == 'train'):\n",
        "      return ['graphstl10_train.pt']\n",
        "    if (self.split == 'test'):\n",
        "      return ['graphstl10_test.pt']\n",
        "    \n",
        "    return []\n",
        "\n",
        "  def download(self):\n",
        "    pass\n",
        "\n",
        "  def process(self):\n",
        "    def crop(image,pc_height,pc_width):\n",
        "      im_width, im_height = image.size\n",
        "      for i in range(im_height//pc_height):\n",
        "        for j in range(im_width//pc_width):\n",
        "          box = (j*pc_width, i*pc_height, (j+1)*pc_width, (i+1)*pc_height)\n",
        "          yield image.crop(box)\n",
        "\n",
        "    data_list = []\n",
        "\n",
        "    preprocess = transforms.Compose([transforms.Resize(256),\n",
        "                                        transforms.CenterCrop(224),\n",
        "                                        transforms.ToTensor(),\n",
        "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "    resnet50 = models.resnet50(pretrained=True)\n",
        "    resnet50.fc = nn.Identity()\n",
        "\n",
        "    for param in resnet50.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    resnet50.to(device)\n",
        "\n",
        "    source_nodes = [i for i in range(0,4) for j in range(0,4)]\n",
        "    target_nodes = [j for i in range(0,4) for j in range(0,4)]\n",
        "    edge_index = torch.tensor([source_nodes, target_nodes],dtype = torch.long)\n",
        "\n",
        "    for imid, (image, label) in enumerate(self.dataset):\n",
        "      # neighbors = np.arange(imid, imid+4)\n",
        "      # mask = [1]*len(neighbors)\n",
        "      im_height, im_width = image.size\n",
        "      pc_height, pc_width = im_height//2, im_width//2\n",
        "      node_features = []\n",
        "      for pid,piece in enumerate(crop(image, pc_height, pc_width)):\n",
        "        patch = Image.new('RGB', (pc_width, pc_height), 255)\n",
        "        patch.paste(piece)\n",
        "        patch = preprocess(patch)\n",
        "        patch = patch.view(1,*patch.shape)\n",
        "        patch = patch.to(device)\n",
        "        patch = resnet50.forward(patch).to(torch.device('cpu'))\n",
        "        node_features.append(torch.tensor(patch))\n",
        "\n",
        "      x = torch.cat(node_features)\n",
        "\n",
        "      y = torch.tensor(label).unsqueeze(0)\n",
        "\n",
        "      data = Data(x=x, edge_index=edge_index.clone(), y=y)\n",
        "\n",
        "      data_list.append(data)\n",
        "\n",
        "    data, slices = self.collate(data_list)\n",
        "    torch.save((data, slices), self.processed_paths[0])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0VbJFx1t3U4",
        "colab_type": "text"
      },
      "source": [
        "# Define custom MessagePassing [WIP]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l-qzzdJxAh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomConv(pyg_nn.MessagePassing):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super(CustomConv, self).__init__(aggr='add') #'add' aggregation\n",
        "    self.lin = nn.Linear(in_channels, out_channels)\n",
        "    self.lin_self = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    # x has shape [N, in_channels]\n",
        "    # edge_index has shape [2, E]\n",
        "\n",
        "    # Transform node feature matrix\n",
        "    self_x = self.lin_self(x)\n",
        "    # x = self.lin(x)\n",
        "\n",
        "    return self_x + self.propagate(edge_index, size=(x.size(0), x.size(0)), x=self.lin(x))\n",
        "  \n",
        "  def message(self, x_i, x_j, edge_index, size):\n",
        "    # Compute messages\n",
        "    # x_j has shape [E, out_channels]\n",
        "    # TODO:\n",
        "    row, col = edge_index\n",
        "    deg = pyg_utils.degree(row, size[0], dtype=x_j.dtype)\n",
        "    deg_inv_sqrt = deg.pow(-0.5)\n",
        "    norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "    return x_j\n",
        "\n",
        "  def update(self, aggr_out):\n",
        "    # aggr_out has shape [N, out_channels]\n",
        "    return aggr_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FisgdFj8uByD",
        "colab_type": "text"
      },
      "source": [
        "# Define the Graph Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Stn49Kp4uFf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VisionGNN(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super(VisionGNN, self).__init__()\n",
        "        \n",
        "    self.dropout = 0.25\n",
        "    self.num_layers = 2\n",
        "    self.hidden = [input_dim, 512, hidden_dim]\n",
        "    # self.resnet = models.resnet50(pretrained=True)\n",
        "    # self.resnet.fc = nn.Identity()\n",
        "\n",
        "    self.convs = nn.ModuleList()\n",
        "    self.lns = nn.ModuleList()\n",
        "\n",
        "    for l in range(self.num_layers):\n",
        "      self.convs.append(self.build_conv_model(self.hidden[l], self.hidden[l+1]))\n",
        "      if (l + 1 < self.num_layers):\n",
        "        self.lns.append(nn.LayerNorm(self.hidden[l+1]))\n",
        "\n",
        "    # post-message-passing\n",
        "    self.post_mp = nn.Sequential(\n",
        "        nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25),\n",
        "        nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "  def build_conv_model(self, input_dim, hidden_dim):\n",
        "      # return CustomConv(input_dim, hidden_dim)\n",
        "      return pyg_nn.GCNConv(input_dim, hidden_dim)\n",
        "      \n",
        "  def forward(self, data):\n",
        "    x, edge_index = data.x, data.edge_index\n",
        "    if data.num_node_features == 0:\n",
        "      x = torch.ones(data.num_nodes, 1)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "      x = self.convs[i](x, edge_index)\n",
        "      emb = x\n",
        "      x = F.relu(x)\n",
        "      x = F.dropout(x, p=self.dropout, training = self.training)\n",
        "      if not i == self.num_layers - 1:\n",
        "        x = self.lns[i](x)\n",
        "\n",
        "    # x = pyg_nn.global_mean_pool(x, data.batch)\n",
        "    x = pyg_nn.global_add_pool(x, data.batch)\n",
        "\n",
        "    x = self.post_mp(x)\n",
        "\n",
        "    return emb, F.log_softmax(x, dim=1)\n",
        "\n",
        "  def loss(self, pred, label):\n",
        "    # Negative log-likelihood\n",
        "    return F.nll_loss(pred, label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVAPxv4G_6ia",
        "colab_type": "code",
        "outputId": "564f2cfa-5122-44a4-ca8d-590378a06076",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "stl10_train = GraphSTL10('/graphstl10/',split='train')\n",
        "stl10_test = GraphSTL10('/graphstl10/',split='test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vbOkPIVEsVl",
        "colab_type": "code",
        "outputId": "32f53317-12a4-4fb6-c638-c140e8df77b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "# train\n",
        "trainloader = DataLoader(stl10_train, batch_size=64, shuffle=True)\n",
        "testloader = DataLoader(stl10_test, batch_size=64, shuffle=True)\n",
        "\n",
        "model = VisionGNN(input_dim=stl10_train.num_node_features, hidden_dim=64, output_dim = 10)\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=0.003)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "epochs = 200\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  model.train()\n",
        "  for batch in trainloader:\n",
        "    optimizer.zero_grad()\n",
        "    batch = batch.to(device)\n",
        "    emb, logits = model(batch)\n",
        "    labels = batch.y\n",
        "    loss = model.loss(logits, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "\n",
        "  running_loss /= len(trainloader.dataset)\n",
        "\n",
        "# test\n",
        "  if (e+1) % 10 == 0:\n",
        "    accuracy = 0\n",
        "    model.eval()\n",
        "    for batch in testloader:\n",
        "      with torch.no_grad():\n",
        "        batch = batch.to(device)\n",
        "        emb, logits = model(batch)\n",
        "        pred = logits.argmax(dim=1)\n",
        "        labels = batch.y\n",
        "      \n",
        "      accuracy += pred.eq(labels).sum().item()\n",
        "\n",
        "    accuracy /= len(testloader.dataset)\n",
        "\n",
        "    print(\"Epoch {}/{}. Loss: {:.4f}. Test accuracy: {:.4f}\".format(e+1, epochs, running_loss, accuracy))\n",
        "      \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 20/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 30/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 40/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 50/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 60/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 70/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 80/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 90/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 100/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 110/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 120/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 130/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 140/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 150/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 160/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 170/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 180/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 190/200. Loss: 0.0364. Test accuracy: 0.1000\n",
            "Epoch 200/200. Loss: 0.0364. Test accuracy: 0.1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8IXpxoQ6bX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}